{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive Learning on the MNIST Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, os, random, copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomHorizontalFlip, RandomCrop, RandomResizedCrop, ColorJitter, GaussianBlur, RandomApply, RandomGrayscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Setting the Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 16):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Preparing the MNIST Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Defining Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "contrastive_transform = Compose(\n",
    "    [RandomHorizontalFlip(), \n",
    "     RandomResizedCrop(size=28, scale=(0.8, 1.0)), \n",
    "     RandomApply([ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1)], p=0.8), \n",
    "     RandomGrayscale(p=0.2), \n",
    "     GaussianBlur(kernel_size=9), \n",
    "     ToTensor(), \n",
    "     Normalize((0.5,), (0.5,))])\n",
    "\n",
    "class CLTransformations(object):\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        xi = self.transform(sample)\n",
    "        xj = self.transform(sample)\n",
    "        return xi, xj\n",
    "    \n",
    "contrastive_transform = CLTransformations(contrastive_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- why those normalisations?\n",
    "- create a table with parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Defining Dataset Size and Batch Size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 5000\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Creating DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=contrastive_transform)\n",
    "trainset = torch.utils.data.Subset(trainset, range(dataset_size))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=contrastive_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('zero', 'one', 'two', 'three', 'four',\n",
    "           'five', 'six', 'seven', 'eight', 'nine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Visualising the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "six   seven nine  zero \n"
     ]
    }
   ],
   "source": [
    "# loading the data\n",
    "show_batch_size = 4\n",
    "show_trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "show_trainloader = torch.utils.data.DataLoader(show_trainset, batch_size=show_batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "show_testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "show_testloader = torch.utils.data.DataLoader(show_testset, batch_size=show_batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('zero', 'one', 'two', 'three', 'four',\n",
    "           'five', 'six', 'seven', 'eight', 'nine')\n",
    "\n",
    "# getting random training images\n",
    "dataiter = iter(show_trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(show_batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- what does imshow do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Contrastive Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Defining and Initialising the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Base Encoder and Projection Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CLModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN Base Encoder\n",
    "        x = torch.relu(self.conv1(x))  # 1x28x28 -> 20x24x24\n",
    "        x = torch.max_pool2d(x, 2, 2)  # 20x24x24 -> 20x12x12\n",
    "        x = torch.relu(self.conv2(x))  # 20x12x12 -> 50x8x8\n",
    "        x = torch.max_pool2d(x, 2, 2)  # 50x8x8 -> 50x4x4\n",
    "        x = x.view(-1, 4 * 4 * 50)     # 50x4x4 -> 800\n",
    "\n",
    "        # Projection Head\n",
    "        x = torch.relu(self.fc1(x))    # 800 -> 500\n",
    "        x = self.fc2(x)                # 500 -> 10\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(hi, hj, temperature=0.5):\n",
    "    # concatenate two sets of features\n",
    "    h = torch.cat([hi, hj], dim=0)\n",
    "\n",
    "    # calculate cosine similarity\n",
    "    cos_sim = F.cosine_similarity(h.unsqueeze(1), h.unsqueeze(0), dim=2)\n",
    "\n",
    "    # remove self-similarity form the matrix\n",
    "    cos_sim = cos_sim.masked_fill(torch.eye(cos_sim.shape[0]).bool(), -1e9)\n",
    "\n",
    "    # for each image, find the positive pair\n",
    "    positive_pairs = torch.cat([torch.arange(hi.shape[0], 2*hi.shape[0]), torch.arange(hi.shape[0])], dim=0)\n",
    "\n",
    "    # compute the InfoNCE loss\n",
    "    loss = F.cross_entropy(cos_sim / temperature, positive_pairs)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- why -1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Initialising Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 Initialising the Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimiser = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 1, Batch 4, Loss: 3.051325464248657\n",
      "Epoch:  1\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 2, Batch 4, Loss: 3.040835428237915\n",
      "Epoch:  2\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 3, Batch 4, Loss: 3.0330147743225098\n",
      "Epoch:  3\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 4, Batch 4, Loss: 3.030378007888794\n",
      "Epoch:  4\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 5, Batch 4, Loss: 3.0303091526031496\n",
      "Epoch:  5\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 6, Batch 4, Loss: 3.034299850463867\n",
      "Epoch:  6\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 7, Batch 4, Loss: 3.025895881652832\n",
      "Epoch:  7\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 8, Batch 4, Loss: 3.017297124862671\n",
      "Epoch:  8\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 9, Batch 4, Loss: 3.0121968269348143\n",
      "Epoch:  9\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 10, Batch 4, Loss: 3.0096388339996336\n",
      "Epoch:  10\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 11, Batch 4, Loss: 3.00756459236145\n",
      "Epoch:  11\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 12, Batch 4, Loss: 3.0028922080993654\n",
      "Epoch:  12\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 13, Batch 4, Loss: 2.9997283458709716\n",
      "Epoch:  13\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 14, Batch 4, Loss: 2.99953556060791\n",
      "Epoch:  14\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 15, Batch 4, Loss: 3.0046159267425536\n",
      "Epoch:  15\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 16, Batch 4, Loss: 2.9977503299713133\n",
      "Epoch:  16\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 17, Batch 4, Loss: 2.991482639312744\n",
      "Epoch:  17\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 18, Batch 4, Loss: 2.9892943859100343\n",
      "Epoch:  18\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 19, Batch 4, Loss: 2.9849292278289794\n",
      "Epoch:  19\n",
      "     Batch:  0\n",
      "     Batch:  1\n",
      "     Batch:  2\n",
      "     Batch:  3\n",
      "     Batch:  4\n",
      "     Epoch 20, Batch 4, Loss: 2.980553913116455\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    batch = 0\n",
    "    print(\"Epoch: \", epoch)\n",
    "    for (xi, xj), _ in trainloader:\n",
    "        print(\"     Batch: \", batch)\n",
    "        batch += 1\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # forward \n",
    "        hi, hj = model(xi), model(xj)\n",
    "        loss = contrastive_loss(hi, hj)\n",
    "\n",
    "        # backward + optimise\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if batch % 10 == 5:\n",
    "            print(f'     Epoch {epoch + 1}, Batch {batch - 1}, Loss: {running_loss / 10}')\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Linear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 With Contrastive Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Loading the Pretrained Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataloader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xi, target in dataloader:\n",
    "            feature = model(xi)\n",
    "            features.append(feature)\n",
    "            labels.append(target)\n",
    "\n",
    "    return torch.cat(features), torch.cat(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_transforms = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "\n",
    "linear_dataset = datasets.MNIST('./data', train=True, download=True, transform=linear_transforms)\n",
    "linear_trainloader = DataLoader(linear_dataset, batch_size=linear_batch_size, shuffle=True)\n",
    "\n",
    "features, labels = extract_features(linear_trainloader, model)\n",
    "linear_dataset = torch.utils.data.TensorDataset(features, labels)\n",
    "linear_trainloader = DataLoader(linear_dataset, batch_size=linear_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Initialising the Linear Classifier and Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_classifier = nn.Linear(10, 10)\n",
    "linear_optimiser = optim.Adam(linear_classifier.parameters(), lr=linear_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Linear Classification With Contrastive Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] loss: 7.15345, accuracy: 45.675\n",
      "[Epoch: 2] loss: 0.94978, accuracy: 78.025\n",
      "[Epoch: 3] loss: 0.65344, accuracy: 82.188\n",
      "[Epoch: 4] loss: 0.56297, accuracy: 83.342\n",
      "[Epoch: 5] loss: 0.51677, accuracy: 83.905\n",
      "[Epoch: 6] loss: 0.49294, accuracy: 84.222\n",
      "[Epoch: 7] loss: 0.47834, accuracy: 84.445\n",
      "[Epoch: 8] loss: 0.46834, accuracy: 84.775\n",
      "[Epoch: 9] loss: 0.46101, accuracy: 84.947\n",
      "[Epoch: 10] loss: 0.45572, accuracy: 84.982\n",
      "[Epoch: 11] loss: 0.45144, accuracy: 85.190\n",
      "[Epoch: 12] loss: 0.44744, accuracy: 85.307\n",
      "[Epoch: 13] loss: 0.44506, accuracy: 85.263\n",
      "[Epoch: 14] loss: 0.44329, accuracy: 85.408\n",
      "[Epoch: 15] loss: 0.44097, accuracy: 85.487\n",
      "[Epoch: 16] loss: 0.43967, accuracy: 85.492\n",
      "[Epoch: 17] loss: 0.43927, accuracy: 85.585\n",
      "[Epoch: 18] loss: 0.43805, accuracy: 85.647\n",
      "[Epoch: 19] loss: 0.43879, accuracy: 85.585\n",
      "[Epoch: 20] loss: 0.43743, accuracy: 85.542\n",
      "[Epoch: 21] loss: 0.43703, accuracy: 85.668\n",
      "[Epoch: 22] loss: 0.43667, accuracy: 85.617\n",
      "[Epoch: 23] loss: 0.43676, accuracy: 85.633\n",
      "[Epoch: 24] loss: 0.43581, accuracy: 85.717\n",
      "[Epoch: 25] loss: 0.43590, accuracy: 85.662\n",
      "[Epoch: 26] loss: 0.43619, accuracy: 85.632\n",
      "[Epoch: 27] loss: 0.43567, accuracy: 85.663\n",
      "[Epoch: 28] loss: 0.43656, accuracy: 85.663\n",
      "[Epoch: 29] loss: 0.43515, accuracy: 85.782\n",
      "[Epoch: 30] loss: 0.43615, accuracy: 85.607\n",
      "[Epoch: 31] loss: 0.43663, accuracy: 85.675\n",
      "[Epoch: 32] loss: 0.43518, accuracy: 85.680\n",
      "[Epoch: 33] loss: 0.43582, accuracy: 85.643\n",
      "[Epoch: 34] loss: 0.43590, accuracy: 85.735\n",
      "[Epoch: 35] loss: 0.43597, accuracy: 85.685\n",
      "[Epoch: 36] loss: 0.43565, accuracy: 85.628\n",
      "[Epoch: 37] loss: 0.43520, accuracy: 85.645\n",
      "[Epoch: 38] loss: 0.43557, accuracy: 85.640\n",
      "[Epoch: 39] loss: 0.43543, accuracy: 85.665\n",
      "[Epoch: 40] loss: 0.43499, accuracy: 85.715\n",
      "[Epoch: 41] loss: 0.43584, accuracy: 85.618\n",
      "[Epoch: 42] loss: 0.43524, accuracy: 85.702\n",
      "[Epoch: 43] loss: 0.43531, accuracy: 85.583\n",
      "[Epoch: 44] loss: 0.43530, accuracy: 85.690\n",
      "[Epoch: 45] loss: 0.43653, accuracy: 85.657\n",
      "[Epoch: 46] loss: 0.43547, accuracy: 85.655\n",
      "[Epoch: 47] loss: 0.43518, accuracy: 85.738\n",
      "[Epoch: 48] loss: 0.43601, accuracy: 85.702\n",
      "[Epoch: 49] loss: 0.43495, accuracy: 85.652\n",
      "[Epoch: 50] loss: 0.43566, accuracy: 85.633\n",
      "[Epoch: 51] loss: 0.43506, accuracy: 85.628\n",
      "[Epoch: 52] loss: 0.43607, accuracy: 85.612\n",
      "[Epoch: 53] loss: 0.43554, accuracy: 85.680\n",
      "[Epoch: 54] loss: 0.43470, accuracy: 85.712\n",
      "[Epoch: 55] loss: 0.43563, accuracy: 85.720\n",
      "[Epoch: 56] loss: 0.43476, accuracy: 85.705\n",
      "[Epoch: 57] loss: 0.43567, accuracy: 85.777\n",
      "[Epoch: 58] loss: 0.43521, accuracy: 85.690\n",
      "[Epoch: 59] loss: 0.43496, accuracy: 85.717\n",
      "[Epoch: 60] loss: 0.43552, accuracy: 85.697\n",
      "[Epoch: 61] loss: 0.43561, accuracy: 85.665\n",
      "[Epoch: 62] loss: 0.43478, accuracy: 85.658\n",
      "[Epoch: 63] loss: 0.43511, accuracy: 85.737\n",
      "[Epoch: 64] loss: 0.43531, accuracy: 85.660\n",
      "[Epoch: 65] loss: 0.43656, accuracy: 85.597\n",
      "[Epoch: 66] loss: 0.43528, accuracy: 85.662\n",
      "[Epoch: 67] loss: 0.43534, accuracy: 85.677\n",
      "[Epoch: 68] loss: 0.43526, accuracy: 85.715\n",
      "[Epoch: 69] loss: 0.43725, accuracy: 85.603\n",
      "[Epoch: 70] loss: 0.43488, accuracy: 85.747\n",
      "[Epoch: 71] loss: 0.43505, accuracy: 85.697\n",
      "[Epoch: 72] loss: 0.43563, accuracy: 85.723\n",
      "[Epoch: 73] loss: 0.43611, accuracy: 85.597\n",
      "[Epoch: 74] loss: 0.43553, accuracy: 85.688\n",
      "[Epoch: 75] loss: 0.43486, accuracy: 85.583\n",
      "[Epoch: 76] loss: 0.43559, accuracy: 85.595\n",
      "[Epoch: 77] loss: 0.43529, accuracy: 85.657\n",
      "[Epoch: 78] loss: 0.43543, accuracy: 85.697\n",
      "[Epoch: 79] loss: 0.43561, accuracy: 85.675\n",
      "[Epoch: 80] loss: 0.43520, accuracy: 85.697\n",
      "[Epoch: 81] loss: 0.43539, accuracy: 85.657\n",
      "[Epoch: 82] loss: 0.43512, accuracy: 85.713\n",
      "[Epoch: 83] loss: 0.43590, accuracy: 85.672\n",
      "[Epoch: 84] loss: 0.43584, accuracy: 85.710\n",
      "[Epoch: 85] loss: 0.43577, accuracy: 85.672\n",
      "[Epoch: 86] loss: 0.43572, accuracy: 85.763\n",
      "[Epoch: 87] loss: 0.43538, accuracy: 85.587\n",
      "[Epoch: 88] loss: 0.43587, accuracy: 85.615\n",
      "[Epoch: 89] loss: 0.43475, accuracy: 85.738\n",
      "[Epoch: 90] loss: 0.43547, accuracy: 85.597\n",
      "[Epoch: 91] loss: 0.43570, accuracy: 85.648\n",
      "[Epoch: 92] loss: 0.43607, accuracy: 85.573\n",
      "[Epoch: 93] loss: 0.43479, accuracy: 85.663\n",
      "[Epoch: 94] loss: 0.43518, accuracy: 85.673\n",
      "[Epoch: 95] loss: 0.43501, accuracy: 85.687\n",
      "[Epoch: 96] loss: 0.43487, accuracy: 85.610\n",
      "[Epoch: 97] loss: 0.43498, accuracy: 85.720\n",
      "[Epoch: 98] loss: 0.43526, accuracy: 85.673\n",
      "[Epoch: 99] loss: 0.43546, accuracy: 85.692\n",
      "[Epoch: 100] loss: 0.43554, accuracy: 85.620\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch, data in enumerate(linear_trainloader, 0):\n",
    "        features, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        linear_optimiser.zero_grad()\n",
    "\n",
    "        # forward \n",
    "        outputs = linear_classifier(features)\n",
    "\n",
    "        # loss\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "\n",
    "        # accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # optimise\n",
    "        linear_optimiser.step()\n",
    "\n",
    "    # print statistics\n",
    "    accuracy = correct / total * 100\n",
    "    print('[Epoch: %d] loss: %.5f, accuracy: %.3f' % (epoch + 1, running_loss / (batch+1), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Without Contrastive Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_dataset = datasets.MNIST('./data', train=True, download=True, transform=linear_transforms)\n",
    "linear_trainloader = DataLoader(linear_dataset, batch_size=linear_batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Initialising the Linear Classifier and Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_classifier = nn.Linear(28*28, 10)\n",
    "linear_optimiser = optim.Adam(linear_classifier.parameters(), lr=linear_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Linear Classification Without Contrastive Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] loss: 0.66095, accuracy: 82.643\n",
      "[Epoch: 2] loss: 0.36965, accuracy: 89.618\n",
      "[Epoch: 3] loss: 0.33349, accuracy: 90.492\n",
      "[Epoch: 4] loss: 0.31657, accuracy: 90.938\n",
      "[Epoch: 5] loss: 0.30648, accuracy: 91.222\n",
      "[Epoch: 6] loss: 0.29840, accuracy: 91.530\n",
      "[Epoch: 7] loss: 0.29253, accuracy: 91.792\n",
      "[Epoch: 8] loss: 0.29005, accuracy: 91.772\n",
      "[Epoch: 9] loss: 0.28635, accuracy: 91.918\n",
      "[Epoch: 10] loss: 0.28342, accuracy: 91.972\n",
      "[Epoch: 11] loss: 0.28029, accuracy: 92.168\n",
      "[Epoch: 12] loss: 0.27812, accuracy: 92.198\n",
      "[Epoch: 13] loss: 0.27644, accuracy: 92.307\n",
      "[Epoch: 14] loss: 0.27563, accuracy: 92.263\n",
      "[Epoch: 15] loss: 0.27143, accuracy: 92.362\n",
      "[Epoch: 16] loss: 0.27220, accuracy: 92.343\n",
      "[Epoch: 17] loss: 0.27021, accuracy: 92.478\n",
      "[Epoch: 18] loss: 0.27040, accuracy: 92.428\n",
      "[Epoch: 19] loss: 0.26772, accuracy: 92.538\n",
      "[Epoch: 20] loss: 0.26672, accuracy: 92.493\n",
      "[Epoch: 21] loss: 0.26613, accuracy: 92.520\n",
      "[Epoch: 22] loss: 0.26517, accuracy: 92.648\n",
      "[Epoch: 23] loss: 0.26526, accuracy: 92.522\n",
      "[Epoch: 24] loss: 0.26285, accuracy: 92.597\n",
      "[Epoch: 25] loss: 0.26282, accuracy: 92.650\n",
      "[Epoch: 26] loss: 0.26299, accuracy: 92.562\n",
      "[Epoch: 27] loss: 0.26206, accuracy: 92.662\n",
      "[Epoch: 28] loss: 0.26194, accuracy: 92.672\n",
      "[Epoch: 29] loss: 0.25938, accuracy: 92.815\n",
      "[Epoch: 30] loss: 0.26004, accuracy: 92.788\n",
      "[Epoch: 31] loss: 0.25956, accuracy: 92.730\n",
      "[Epoch: 32] loss: 0.25984, accuracy: 92.795\n",
      "[Epoch: 33] loss: 0.25862, accuracy: 92.772\n",
      "[Epoch: 34] loss: 0.25681, accuracy: 92.878\n",
      "[Epoch: 35] loss: 0.25773, accuracy: 92.745\n",
      "[Epoch: 36] loss: 0.25855, accuracy: 92.672\n",
      "[Epoch: 37] loss: 0.25607, accuracy: 92.878\n",
      "[Epoch: 38] loss: 0.25580, accuracy: 92.832\n",
      "[Epoch: 39] loss: 0.25539, accuracy: 92.897\n",
      "[Epoch: 40] loss: 0.25552, accuracy: 92.877\n",
      "[Epoch: 41] loss: 0.25512, accuracy: 92.890\n",
      "[Epoch: 42] loss: 0.25437, accuracy: 92.887\n",
      "[Epoch: 43] loss: 0.25458, accuracy: 92.942\n",
      "[Epoch: 44] loss: 0.25517, accuracy: 92.828\n",
      "[Epoch: 45] loss: 0.25341, accuracy: 92.920\n",
      "[Epoch: 46] loss: 0.25328, accuracy: 93.023\n",
      "[Epoch: 47] loss: 0.25314, accuracy: 92.900\n",
      "[Epoch: 48] loss: 0.25309, accuracy: 92.880\n",
      "[Epoch: 49] loss: 0.25146, accuracy: 93.032\n",
      "[Epoch: 50] loss: 0.25249, accuracy: 93.003\n",
      "[Epoch: 51] loss: 0.25112, accuracy: 93.035\n",
      "[Epoch: 52] loss: 0.25242, accuracy: 92.993\n",
      "[Epoch: 53] loss: 0.25102, accuracy: 92.977\n",
      "[Epoch: 54] loss: 0.25097, accuracy: 93.007\n",
      "[Epoch: 55] loss: 0.25143, accuracy: 92.875\n",
      "[Epoch: 56] loss: 0.25086, accuracy: 93.012\n",
      "[Epoch: 57] loss: 0.24994, accuracy: 93.000\n",
      "[Epoch: 58] loss: 0.24913, accuracy: 93.117\n",
      "[Epoch: 59] loss: 0.24857, accuracy: 93.088\n",
      "[Epoch: 60] loss: 0.25016, accuracy: 93.018\n",
      "[Epoch: 61] loss: 0.25083, accuracy: 93.018\n",
      "[Epoch: 62] loss: 0.24976, accuracy: 93.040\n",
      "[Epoch: 63] loss: 0.24820, accuracy: 93.088\n",
      "[Epoch: 64] loss: 0.24830, accuracy: 93.138\n",
      "[Epoch: 65] loss: 0.24853, accuracy: 93.132\n",
      "[Epoch: 66] loss: 0.24918, accuracy: 93.065\n",
      "[Epoch: 67] loss: 0.24911, accuracy: 93.055\n",
      "[Epoch: 68] loss: 0.24878, accuracy: 93.040\n",
      "[Epoch: 69] loss: 0.24640, accuracy: 93.147\n",
      "[Epoch: 70] loss: 0.24755, accuracy: 93.087\n",
      "[Epoch: 71] loss: 0.24741, accuracy: 93.133\n",
      "[Epoch: 72] loss: 0.24621, accuracy: 93.183\n",
      "[Epoch: 73] loss: 0.24640, accuracy: 93.168\n",
      "[Epoch: 74] loss: 0.24723, accuracy: 93.143\n",
      "[Epoch: 75] loss: 0.24916, accuracy: 92.928\n",
      "[Epoch: 76] loss: 0.24608, accuracy: 93.210\n",
      "[Epoch: 77] loss: 0.24580, accuracy: 93.142\n",
      "[Epoch: 78] loss: 0.24477, accuracy: 93.172\n",
      "[Epoch: 79] loss: 0.24589, accuracy: 93.150\n",
      "[Epoch: 80] loss: 0.24575, accuracy: 93.137\n",
      "[Epoch: 81] loss: 0.24652, accuracy: 93.115\n",
      "[Epoch: 82] loss: 0.24726, accuracy: 93.025\n",
      "[Epoch: 83] loss: 0.24654, accuracy: 93.055\n",
      "[Epoch: 84] loss: 0.24428, accuracy: 93.197\n",
      "[Epoch: 85] loss: 0.24505, accuracy: 93.177\n",
      "[Epoch: 86] loss: 0.24501, accuracy: 93.292\n",
      "[Epoch: 87] loss: 0.24419, accuracy: 93.092\n",
      "[Epoch: 88] loss: 0.24388, accuracy: 93.175\n",
      "[Epoch: 89] loss: 0.24486, accuracy: 93.168\n",
      "[Epoch: 90] loss: 0.24493, accuracy: 93.262\n",
      "[Epoch: 91] loss: 0.24442, accuracy: 93.133\n",
      "[Epoch: 92] loss: 0.24359, accuracy: 93.248\n",
      "[Epoch: 93] loss: 0.24339, accuracy: 93.240\n",
      "[Epoch: 94] loss: 0.24397, accuracy: 93.267\n",
      "[Epoch: 95] loss: 0.24296, accuracy: 93.323\n",
      "[Epoch: 96] loss: 0.24388, accuracy: 93.182\n",
      "[Epoch: 97] loss: 0.24414, accuracy: 93.165\n",
      "[Epoch: 98] loss: 0.24209, accuracy: 93.252\n",
      "[Epoch: 99] loss: 0.24406, accuracy: 93.225\n",
      "[Epoch: 100] loss: 0.24349, accuracy: 93.232\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch, data in enumerate(linear_trainloader, 0):\n",
    "        features, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        linear_optimiser.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        features = features.view(features.size(0), -1)\n",
    "        outputs = linear_classifier(features)\n",
    "\n",
    "        # loss\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "\n",
    "        # accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # optimise\n",
    "        linear_optimiser.step()\n",
    "\n",
    "    # print statistics\n",
    "    accuracy = correct / total * 100\n",
    "    print('[Epoch: %d] loss: %.5f, accuracy: %.3f' % (epoch + 1, running_loss / (batch+1), accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl_mnist_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
